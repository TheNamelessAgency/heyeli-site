<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Welcome to heyELi — Building a Camera That Understands</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="How a nights-and-weekends experiment between Josh Coon and an AI partner evolved into a working multimodal assistant.">
  <link rel="stylesheet" href="/styles.css">
  <meta property="og:title" content="Welcome to heyELi — Building a Camera That Understands">
  <meta property="og:description" content="How a nights-and-weekends experiment between Josh Coon and an AI partner evolved into a working multimodal assistant.">
  <meta property="og:image" content="/assets/og.png">
</head>

<body>
  <header class="nav">
    <a class="brand" href="/"><img src="/assets/logo.png" alt="heyELi logo"><span>heyELi</span></a>
    <nav>
      <a href="/">Home</a>
      <a href="/blog/" aria-current="page">Blog</a>
    </nav>
  </header>

  <main>
    <article class="post">
      <header class="post-header">
        <h1>Welcome to heyELi</h1>
        <p class="meta">Mar 2025 · 3 min read</p>
      </header>

      <p>heyELi began as a quiet experiment — late nights and weekends, a few thousand lines of Swift, and a simple idea: <em>what if a camera could understand what it sees?</em></p>

      <p>My name is <strong>Josh Coon</strong>, and I built heyELi with my AI collaborator, <strong>Alan</strong>. Together we explored how multimodal language models could bridge the gap between what’s seen, said, and understood — not through a lab or a venture fund, but through curiosity, iteration, and a lot of trial and error.</p>

      <p>We didn’t set out to start a company. We set out to learn — to harness the partnership between human intuition and machine precision. Each night, we’d test a new prompt, debug a translation bug, or rebuild the camera layer from scratch. Each weekend, the prototype evolved until one night, it just <em>worked</em>: a working multimodal assistant running on an iPhone, understanding images, text, and voice in real time.</p>

      <h2>What we’re aiming for</h2>
      <ul>
        <li>Instant understanding of what the camera sees</li>
        <li>Guided teaching, fixing, communicating, curating, and creating in real time</li>
        <li>Calm, cinematic UX that feels helpful and human</li>
      </ul>

      <p>What started as a side project is quickly becoming something much bigger — a platform for people to learn, build, and express more naturally. This blog will share the journey: what we’re building, why it matters, and how you can be part of it.</p>

      <p><strong>Augmentation is here.</strong><br>
      No longer waiting for permission. Build the future.</p>

      <hr class="post-divider">
      <p><a href="/blog/">← Back to all posts</a></p>
    </article>
  </main>

  <footer class="footer">
    <p>© 2025 heyELi. All rights reserved.</p>
    <p class="links">
      <a href="/privacy.html">Privacy</a> ·
      <a href="/terms.html">Terms</a> ·
      <a href="mailto:team@heyeli.app">Contact</a> ·
      <a href="https://www.instagram.com/heyeli.app/" target="_blank" rel="noopener noreferrer">Instagram</a>
    </p>
  </footer>
</body>
</html>
